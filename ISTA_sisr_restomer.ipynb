{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISTA_sisr_restomer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from runpy import run_path\n"
      ],
      "metadata": {
        "id": "_bCIcRb40FcE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install hdf5storage\n",
        "import hdf5storage\n",
        "import pandas as pd "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "givyIy2p3jtF",
        "outputId": "acc0a2f2-feab-4a32-abde-48c17422178c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hdf5storage\n",
            "  Downloading hdf5storage-0.1.18-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 680 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.1 in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1->hdf5storage) (1.5.2)\n",
            "Installing collected packages: hdf5storage\n",
            "Successfully installed hdf5storage-0.1.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    parameters = {'inp_channels':1, 'out_channels':1, 'dim':48, 'num_blocks':[4,6,6,8], 'num_refinement_blocks':4, 'heads':[1,2,4,8], 'ffn_expansion_factor':2.66, 'bias':False, 'LayerNorm_type':'BiasFree', 'dual_pixel_task':False}\n",
        "    load_arch = run_path('/content/drive/MyDrive/SRFP/Restormer/basicsr/models/archs/restormer_arch.py')      #os.path.join('models', 'restormer_arch.py'))\n",
        "    model = load_arch['Restormer'](**parameters)\n",
        "    checkpoint = torch.load('/content/drive/MyDrive/SRFP/DPIR/model_zoo/gaussian_gray_denoising_blind.pth') #('/content/drive/MyDrive/SRFP/DPIR/model_zoo/gaussian_gray_denoising_blind.pth'')  #('/content/drive/MyDrive/SRFP/DPIR/model_zoo/gaussian_gray_denoising_sigma50.pth') #('/content/drive/MyDrive/SRFP/DPIR/model_zoo/gaussian_gray_denoising_blind.pth')  #torch.load('/content/drive/MyDrive/SRFP/DPIR/model_zoo/gaussian_color_denoising_blind.pth')\n",
        "    model.load_state_dict(checkpoint['params'], strict=True)\n",
        "    model.eval()\n",
        "    for k, v in model.named_parameters():\n",
        "\n",
        "        v.requires_grad = False\n",
        "    model = model.to(device)\n",
        "    return model    "
      ],
      "metadata": {
        "id": "OQ3RMpe92A-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def proj(im_input, minval, maxval):\n",
        "    im_out = np.where(im_input > maxval, maxval, im_input)\n",
        "    im_out = np.where(im_out < minval, minval, im_out)\n",
        "    return im_out\n",
        "\n",
        "def psnr(x,im_orig):\n",
        "    norm2 = np.mean((x - im_orig) ** 2)\n",
        "    psnr = -10 * np.log10(norm2)\n",
        "    return psnr\n",
        "\n",
        "def funcAtranspose(im_input, mask, fx, fy):\n",
        "    m,n = im_input.shape\n",
        "    fx = int(1/fx)\n",
        "    fy = int(1/fy)\n",
        "    im_inputres = np.zeros([m*fx, m*fy], im_input.dtype)\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            im_inputres[fx*i,fy*j] = im_input[i,j]\n",
        " \n",
        "    m,n = im_inputres.shape\n",
        "    w = len(mask[0])\n",
        "    r = int((w - 1) / 2)\n",
        "    im_inputres = cv2.copyMakeBorder(im_inputres, r, r, r, r, borderType=cv2.BORDER_WRAP)\n",
        "    im_output = cv2.filter2D(im_inputres, -1, mask)\n",
        "    im_output = im_output[r:r+m, r:r+n]\n",
        "    return im_output\n",
        "\n",
        "def funcA(im_input, mask, fx, fy):\n",
        "    m,n = im_input.shape\n",
        "    w = len(mask[0])\n",
        "    r = int((w - 1) / 2)\n",
        "    im_input = cv2.copyMakeBorder(im_input, r, r, r, r, borderType=cv2.BORDER_WRAP)\n",
        "    im_output = cv2.filter2D(im_input, -1, mask)\n",
        "    im_output = im_output[r:r+m, r:r+n]\n",
        "    im_outputres = cv2.resize(im_output, (0,0), fx=fx, fy=fy, interpolation=cv2.INTER_NEAREST)\n",
        "    #print('im_output',im_output.shape,'im_outputres',im_outputres.shape)\n",
        "    return im_outputres"
      ],
      "metadata": {
        "id": "8ZhQnD1j0H3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pnp_fbs_superresolution(model, im_input, im_ref, fx, fy, mask, **opts):\n",
        "\n",
        "    max_list = []\n",
        "    lamda = opts.get('lamda', 2.0)\n",
        "    rho = opts.get('rho', 1.0)\n",
        "    maxitr = opts.get('maxitr', 100)\n",
        "    verbose = opts.get('verbose',1)\n",
        "    sigma = opts.get('sigma', 15)\n",
        "\n",
        "    \"\"\" Initialization. \"\"\"\n",
        "    index = np.nonzero(mask)\n",
        "   # print('im_input',im_input.shape)\n",
        "    y = funcAtranspose(im_input, mask, fx, fy)\n",
        "    #print('y',y.shape)\n",
        "    m, n = y.shape\n",
        "\n",
        "    x = cv2.resize(im_input, (m, n))\n",
        "    #print('shape of x ',x.shape)\n",
        "\n",
        "    \"\"\" Main loop. \"\"\"\n",
        "    for i in range(maxitr):\n",
        "\n",
        "        xold = np.copy(x)\n",
        "\n",
        "        \"\"\" Update gradient. \"\"\"\n",
        "        xoldhat = funcA(x, mask, fx, fy)\n",
        "        gradx = funcAtranspose(xoldhat, mask, fx, fy) - y\n",
        "\n",
        "        \"\"\" Denoising step. \"\"\"\n",
        "\n",
        "        xtilde = np.copy(xold - rho * gradx)\n",
        "\n",
        "        xtilde_torch = np.reshape(xtilde, (1,1,m,n))\n",
        "        xtilde_torch = torch.from_numpy(xtilde_torch).type(torch.FloatTensor).cuda()\n",
        "        r = model(xtilde_torch).cpu().numpy()\n",
        "        r = np.reshape(r, (m,n))\n",
        "        x = 0.5*r + 0.5*xtilde\n",
        "        x = proj(x, 0.0, 1.0)\n",
        "\n",
        "        \"\"\" Monitoring. \"\"\"\n",
        "        max_list.append( psnr(x,im_ref) )\n",
        "        index = max_list.index(np.max(max_list))\n",
        "        if verbose:\n",
        "            print(\"i: {}, \\t psnr: {} ssim= {} \"\\\n",
        "                  .format(i+1, psnr(x,im_ref), compare_ssim(x, im_ref, data_range=1.)))\n",
        "\n",
        "    return x,np.max(max_list),index\n"
      ],
      "metadata": {
        "id": "DTa60wjbTDse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iterate(input_array, rho_ = 4.0, itr_ = 50):\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "      K = 2 # downsampling factor\n",
        "      # ---- load the ground truth ----\n",
        "      im_orig = input_array\n",
        "      # im_orig1 = cv2.imread(input_str,0)/255.0     \n",
        "      # im_orig = im_orig1[:320,:320]#im_orig1[:480,:320]\n",
        "      m,n = im_orig.shape\n",
        "\n",
        "      # ---- blur the image \n",
        "      kernel = cv2.getGaussianKernel(9, 1)\n",
        "      mask = np.outer(kernel, kernel.transpose())\n",
        "      w = len(mask[0])\n",
        "      r = int((w - 1) / 2)\n",
        "      im_orig = cv2.copyMakeBorder(im_orig, r, r, r, r, borderType=cv2.BORDER_WRAP)\n",
        "      im_blur = cv2.filter2D(im_orig, -1, mask)\n",
        "      im_blur = im_blur[r:r+m, r:r+n]\n",
        "      im_orig = im_orig[r:r+m, r:r+n]\n",
        "\n",
        "      # ---- Downsample the image\n",
        "      fx = 1./K\n",
        "      fy = 1./K \n",
        "      im_down = cv2.resize(im_blur, (0,0), fx=fx, fy=fy, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "      # ---- add noise -----\n",
        "      noise_level = 5.0 / 255.0\n",
        "      gauss = np.random.normal(0.0, noise_level, im_down.shape)\n",
        "      im_noisy = im_down + gauss\n",
        "      psnr_final = 0.\n",
        "\n",
        "      # ---- set options -----\n",
        "      sigma = 50\n",
        "      rho = rho_\n",
        "      maxiter = itr_\n",
        "      # ---- load the model ----\n",
        "      model = load_model()#(\"DnCNN\", sigma)\n",
        "\n",
        "      opts = dict(sigma = sigma, rho = rho, maxitr = maxiter, verbose = False)\n",
        "\n",
        "      # ---- plug and play -----\n",
        "      out,max, index = pnp_fbs_superresolution(model, im_noisy, im_orig, fx, fy, mask, **opts)\n",
        "      \n",
        "      # ---- results ----\n",
        "      psnr_ours = psnr(out, im_orig)\n",
        "      ssim_ours = compare_ssim(out, im_orig, data_range=1.)\n",
        "      print('sigma = {}, rho = {} - PNSR: {}, SSIM = {}  Max : {}, Index : {}'.format(sigma, rho, psnr_ours, ssim_ours,max,index))\n",
        "  return  (out, sigma, rho, psnr_ours, ssim_ours,max,index)\n"
      ],
      "metadata": {
        "id": "2OpDaheKTPbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "def calculate_psnr(img1, img2):\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    mse = np.mean((img1 - img2)**2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    return 20 * math.log10(255.0 / math.sqrt(mse))"
      ],
      "metadata": {
        "id": "a2AtIfh5jleK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def driver(rho_ = 10, itr_= 5):\n",
        "  temp = '/content/drive/MyDrive/SRFP/DPIR/testsets/set3c/leaves.png'\n",
        "  im_orig = cv2.imread(temp)/255.0\n",
        "\n",
        "  #------------------------- splitting each channel \n",
        "  im_orig_r = im_orig[:,:,0]\n",
        "  im_orig_g = im_orig[:,:,1]\n",
        "  im_orig_b = im_orig[:,:,2]\n",
        "\n",
        "  #-------------------------Predicting each channel \n",
        "  sum = 0\n",
        "  avg_psnr = 0 \n",
        "  _rho_ = rho_\n",
        "  _itr_ = itr_\n",
        "  out_r , sigma, rho, psnr_ours, ssim_ours,max,index = iterate(im_orig_r,rho_ = _rho_, itr_ = _itr_) ; sum = sum + index  \n",
        "  avg_psnr = avg_psnr + max\n",
        "  out_g , sigma, rho, psnr_ours, ssim_ours,max,index = iterate(im_orig_g,rho_ = _rho_, itr_ = _itr_) ; sum = sum + index \n",
        "  avg_psnr = avg_psnr + max\n",
        "  out_b , sigma, rho, psnr_ours, ssim_ours,max,index = iterate(im_orig_b,rho_ = _rho_, itr_ = _itr_) ; sum = sum + index  \n",
        "  avg_psnr = avg_psnr + max\n",
        "\n",
        "  print('give_itr',math.ceil(sum/3), 'with_iter_set ****',avg_psnr/3)\n",
        "\n",
        "  #-------------------------Merginng all channels together\n",
        "  im_recon = np.ones(im_orig.shape, out_b.dtype)\n",
        "  im_recon[:,:,0] = np.uint8((out_r*255.0).round())\n",
        "  im_recon[:,:,1] = np.uint8((out_g*255.0).round())\n",
        "  im_recon[:,:,2] = np.uint8((out_b*255.0).round()) \n",
        "  im_recon = im_recon.astype('uint8')\n",
        "\n",
        "  #-------------------------Psnr\n",
        "  psnr = calculate_psnr(im_recon,cv2.imread(temp))\n",
        "  print('current psnr',psnr)\n",
        "  cv2.imwrite('LISTASUPERBLIND'+str(rho_)+'itr'+str(itr_)+str(psnr) +'.png', im_recon)\n"
      ],
      "metadata": {
        "id": "P8pAemGdjokj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}